# run_full_pipeline.py
"""
â”œâ”€â”€LLM_signal_generation/
    â”œâ”€â”€ preprocess.py
    â”œâ”€â”€ embedder.py
    â”œâ”€â”€ scorer.py
    â”œâ”€â”€ aggregator.py
    â””â”€â”€ run_pipeline.py

â”œâ”€â”€digital_state_estimator.py
â””â”€â”€valuation.py

â””â”€â”€run_full_pipeline.py

ä¸»è¿è¡Œæ–‡ä»¶ï¼šå°†æ•´ä¸ª3.1 â†’ 3.2 â†’ 3.3æµç¨‹ä¸²è”ä¸ºä¸€ä½“åŒ–æµç¨‹
åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š
    1. æ–‡æœ¬åµŒå…¥ â†’ è¯­ä¹‰è¯„åˆ† â†’ ç»´åº¦æ‰“åˆ† (R^{(k)}_{i,t})
    2. çŠ¶æ€ä¼°è®¡ (Î¸^{(k)}_{i,t}) via Kalman filter
    3. ä¸è´¢åŠ¡/å®è§‚æ‹¼æ¥ â†’ æ¨¡å‹ä¼°å€¼ â†’ SHAPè§£é‡Š
"""

from LLM_signal_generation.run_pipeline import run_pipeline
from digital_asset_valuation.digital_state_estimator import run_state_estimation
from digital_asset_valuation.valuation import compute_valuation_model_with_shap, generate_shap_visualizations, \
    plot_feature_importance, save_model_to_disk

import pandas as pd
import numpy as np

# âœ… ç¤ºä¾‹åŸå§‹è¾“å…¥ï¼ˆå¯æ›¿æ¢ä¸ºçœŸå®æ–‡æœ¬æ•°æ®ï¼‰
example_input = [
    {"firm_id": "BYD", "date": "2025-05-01", "text": "BYD announced a strategic expansion plan."},
    {"firm_id": "BYD", "date": "2025-05-01", "text": "The brand reputation of BYD surged on Google Trends."},
    {"firm_id": "BYD", "date": "2025-05-01", "text": "The company filed 12 new battery patents."},
    {"firm_id": "TSLA", "date": "2025-05-01", "text": "Tesla launched its tokenized loyalty platform."},
    {"firm_id": "TSLA", "date": "2025-05-01",
     "text": "Market perception of Tesla fell sharply after leadership changes."}
]

if __name__ == "__main__":
    print("ğŸš€ Step 1: LLM è¯­ä¹‰æ‰“åˆ† Pipeline å¼€å§‹...")
    df_R = run_pipeline(example_input)

    score_cols = ['executive', 'brand', 'patent', 'crypto', 'reputation']

    print("\nğŸ” Step 2: çŠ¶æ€ä¼°è®¡ - Kalman Filter æ»¤æ³¢")
    df_theta = run_state_estimation(df_R, score_cols)

    print("\nğŸ“ Step 3: æ„å»ºä¼°å€¼æ¨¡å‹è¾“å…¥æ•°æ®ï¼ˆæ‹¼æ¥è´¢åŠ¡ + å®è§‚ï¼‰")

    # åˆæˆè´¢åŠ¡ + å®è§‚æŒ‡æ ‡ + ç›®æ ‡å˜é‡ï¼ˆæ­¤å¤„ä¸ºç¤ºä¾‹æ•°æ®ï¼‰
    np.random.seed(42)
    df_theta["roe"] = np.random.normal(0.12, 0.05, len(df_theta))
    df_theta["debt_ratio"] = np.random.normal(0.4, 0.05, len(df_theta))
    df_theta["interest_rate"] = np.random.normal(0.03, 0.005, len(df_theta))
    df_theta["epu_index"] = np.random.normal(130, 30, len(df_theta))

    # æ„é€  market valueï¼ˆä½œä¸ºè®­ç»ƒç›®æ ‡ï¼‰ç”¨äºç¤ºä¾‹éªŒè¯
    df_theta["market_value"] = (
            50 + 20 * df_theta["theta_brand"] +
            25 * df_theta["theta_patent"] +
            10 * df_theta["theta_crypto"] +
            15 * df_theta["theta_reputation"] +
            18 * df_theta["theta_executive"] +
            80 * df_theta["roe"] -
            30 * df_theta["debt_ratio"] -
            200 * df_theta["interest_rate"] -
            0.1 * df_theta["epu_index"] +
            np.random.normal(0, 3, len(df_theta))
    )

    # é€‰æ‹©ç‰¹å¾åˆ—å’Œç›®æ ‡åˆ—
    feature_cols = [
        "theta_brand", "theta_patent", "theta_crypto",
        "theta_reputation", "theta_executive",
        "roe", "debt_ratio", "interest_rate", "epu_index"
    ]
    target_col = "market_value"

    print("\nğŸ¯ Step 4: æ¨¡å‹è®­ç»ƒ + SHAP åˆ†æ + ä¿å­˜æ¨¡å‹")
    model, shap_values, explainer, metrics, X_train = compute_valuation_model_with_shap(
        df_theta, feature_cols, target_col
    )

    print(f"\nğŸ“ˆ æ¨¡å‹æ€§èƒ½:\n - MSE: {metrics['mse']:.2f}\n - RÂ²:  {metrics['r2']:.2f}")

    generate_shap_visualizations(explainer, shap_values, X_train)
    plot_feature_importance(model, X_train.columns)
    save_model_to_disk(model)

    print("\nâœ… å…¨æµç¨‹æ‰§è¡Œå®Œæˆã€‚ä¼°å€¼æ¨¡å‹ä¸ SHAP è§£é‡Šç»“æœå·²è¾“å‡ºã€‚")
