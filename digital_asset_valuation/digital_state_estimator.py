# digital_state_estimator.py

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
from LLM_signal_generation.run_pipeline import run_pipeline

def initialize_prior(df: pd.DataFrame, score_cols: list):
    """
    åˆå§‹åŒ–çŠ¶æ€ Î¼_0 å’Œ Î£_0ï¼Œç¡®ä¿æ‰€æœ‰ç»´åº¦éž NaNã€‚
    - è‹¥æŸåˆ—å…¨ä¸º NaNï¼Œåˆ™è®¾ä¸ºé»˜è®¤å€¼ 0.5
    - åæ–¹å·®ä¸­çš„ NaN æ›¿æ¢ä¸ºé»˜è®¤å°å€¼
    """
    sub_df = df[score_cols]

    # å‡å€¼å¤„ç†ï¼šNaN â†’ 0.5
    mu0 = sub_df.mean(skipna=True).fillna(0.5).values

    # åæ–¹å·®å¤„ç†
    sigma0 = sub_df.cov(min_periods=1)
    sigma0 = sigma0.fillna(0.01).values

    return mu0, sigma0

def kalman_update(mu_pred, sigma_pred, R_obs, H, R_cov):
    """
    æ‰§è¡Œ Kalman Filter çš„è§‚æµ‹æ›´æ–°
    å‚æ•°ï¼š
        mu_pred: é¢„æµ‹çŠ¶æ€ Î¼_{t|t-1}
        sigma_pred: é¢„æµ‹åæ–¹å·® Î£_{t|t-1}
        R_obs: è§‚æµ‹å‘é‡ R_{i,t}^{(k)}ï¼Œç¼ºå¤±å€¼ NaN
        H: è§‚æµ‹çŸ©é˜µï¼ˆé€šå¸¸ä¸ºå•ä½é˜µï¼Œå°ºå¯¸æ ¹æ®è§‚æµ‹å€¼è€Œå˜ï¼‰
        R_cov: è§‚æµ‹å™ªå£°åæ–¹å·®
    è¿”å›žï¼š
        mu_post, sigma_post: åŽéªŒä¼°è®¡
    """
    mask = ~np.isnan(R_obs)
    if not np.any(mask):
        return mu_pred, sigma_pred  # æ— è§‚æµ‹ï¼Œä¸æ›´æ–°

    R_obs = R_obs[mask]
    H_t = H[mask]
    R_t = R_cov[np.ix_(mask, mask)]

    y = R_obs - H_t @ mu_pred
    S = H_t @ sigma_pred @ H_t.T + R_t
    K = sigma_pred @ H_t.T @ np.linalg.inv(S)

    mu_post = mu_pred + K @ y
    sigma_post = (np.eye(len(mu_pred)) - K @ H_t) @ sigma_pred
    return mu_post, sigma_post

def run_state_estimation(df: pd.DataFrame, score_cols: list, rho=0.95, q_scale=0.01, r_scale=0.05):
    """
    å¯¹å¤šä¸ªå…¬å¸è¿›è¡ŒçŠ¶æ€ç©ºé—´ä¼°è®¡ï¼Œè¾“å‡º Î¸_hatï¼ˆå‡å€¼ä¼°è®¡ï¼‰
    """
    firms = df['firm_id'].unique()
    results = []

    for firm in firms:
        df_firm = df[df['firm_id'] == firm].sort_values("date")
        T = len(df_firm)

        mu0, sigma0 = initialize_prior(df_firm, score_cols)
        Q = q_scale * np.eye(len(score_cols))
        R_cov = r_scale * np.eye(len(score_cols))
        H = np.eye(len(score_cols))

        mu_hist = []
        mu_t = mu0
        sigma_t = sigma0

        for _, row in df_firm.iterrows():
            R_obs = row[score_cols].astype(float).values  # ðŸ‘ˆ å¼ºåˆ¶è½¬ä¸º float

            # çŠ¶æ€é¢„æµ‹
            mu_pred = rho * mu_t
            sigma_pred = rho ** 2 * sigma_t + Q

            # Kalman æ›´æ–°
            mu_t, sigma_t = kalman_update(mu_pred, sigma_pred, R_obs, H, R_cov)

            result_row = {
                "firm_id": row["firm_id"],
                "date": row["date"]
            }
            for i, k in enumerate(score_cols):
                result_row[f"theta_{k}"] = mu_t[i]
            mu_hist.append(result_row)

        results.extend(mu_hist)

    return pd.DataFrame(results)

# ===================== æ–°å¢žå¯è§†åŒ–æ”¯æŒå‡½æ•° =====================

def run_state_estimation_with_trace(df: pd.DataFrame, score_cols: list,
                                     rho=0.95, q_scale=0.01, r_scale=0.05):
    """
    å’Œ run_state_estimation ç±»ä¼¼ï¼Œä½†è¿”å›ž trace æ—¥å¿—ä¾›å¯è§†åŒ–ã€‚
    """
    firms = df['firm_id'].unique()
    results = []
    trace_records = []

    for firm in firms:
        df_firm = df[df['firm_id'] == firm].sort_values("date")
        T = len(df_firm)

        mu0, sigma0 = initialize_prior(df_firm, score_cols)
        Q = q_scale * np.eye(len(score_cols))
        R_cov = r_scale * np.eye(len(score_cols))
        H = np.eye(len(score_cols))

        mu_t = mu0
        sigma_t = sigma0

        for _, row in df_firm.iterrows():
            R_obs = row[score_cols].astype(float).values

            mu_pred = rho * mu_t
            sigma_pred = rho ** 2 * sigma_t + Q

            mu_post, sigma_post = kalman_update(mu_pred, sigma_pred, R_obs, H, R_cov)

            result_row = {
                "firm_id": row["firm_id"],
                "date": row["date"]
            }
            for i, k in enumerate(score_cols):
                result_row[f"theta_{k}"] = mu_post[i]

            results.append(result_row)
            trace_records.append({
                "firm_id": row["firm_id"],
                "date": row["date"],
                "mu_pred": mu_pred.copy(),
                "mu_post": mu_post.copy(),
                "K_gain": sigma_pred @ H.T @ np.linalg.inv(H @ sigma_pred @ H.T + R_cov),
                "R_obs": R_obs.copy()
            })

            mu_t, sigma_t = mu_post, sigma_post

    return pd.DataFrame(results), trace_records

def plot_state_traces(trace_records, score_cols, firm_name):
    """
    å¯è§†åŒ– Kalman çŠ¶æ€ä¼°è®¡è¿‡ç¨‹ï¼ˆPrior vs Posteriorï¼‰
    - trace_records: run_state_estimation_with_trace ä¸­è¿”å›žçš„ trace åˆ—è¡¨
    - score_cols: æ‰€æœ‰ç»´åº¦å
    - firm_id: å¯é€‰ï¼Œåªç”»æŸå…¬å¸
    """

    # ðŸ‘‰ æ‰“å°è°ƒè¯•ä¿¡æ¯
    # print("âœ… trace_records ç¤ºä¾‹ï¼š", trace_records[:1])
    # print("âœ… ç»´åº¦å score_colsï¼š", score_cols)

    # 1. æž„é€  DataFrame
    df_trace = pd.DataFrame(trace_records)

    # 2. ä¿®å¤æ—¥æœŸæ ¼å¼
    df_trace["date"] = pd.to_datetime(
        df_trace["date"].astype(str).str.strip().str.replace(r"-([1-9])$", r"-0\1", regex=True),
        format="%Y-%m",
        errors="coerce"
    )
    df_trace = df_trace.dropna(subset=["date"])  # é¿å…ç”»å›¾å¤±è´¥

    # 3. è¿‡æ»¤æŒ‡å®šå…¬å¸
    df_trace = df_trace[df_trace["firm_id"] == firm_name]
    if df_trace.empty:
        all_firms = pd.DataFrame(trace_records)["firm_id"].unique()
        print(f"âš ï¸ å…¬å¸ '{firm_name}' ä¸å­˜åœ¨ trace ä¸­ã€‚å¯é€‰å…¬å¸ååŒ…æ‹¬ï¼š{list(all_firms)}")
        return

    # 4. æ£€æŸ¥ trace æ˜¯å¦æœ‰æ•ˆ
    if df_trace.empty or not {"mu_pred", "mu_post"}.issubset(df_trace.columns):
        print("âš ï¸ No valid data to plot.")
        return

    # 5. å‡†å¤‡ç”»å¸ƒ
    fig, axs = plt.subplots(len(score_cols), 1, figsize=(10, 3 * len(score_cols)), sharex=True)

    if len(score_cols) == 1:
        axs = [axs]  # ç»Ÿä¸€å¤„ç†

    # 6. åˆ†åˆ«ç»˜å›¾
    for i, dim in enumerate(score_cols):
        mu_preds = df_trace["mu_pred"].apply(lambda x: x[i] if isinstance(x, (list, np.ndarray)) and len(x) > i else np.nan)
        mu_posts = df_trace["mu_post"].apply(lambda x: x[i] if isinstance(x, (list, np.ndarray)) and len(x) > i else np.nan)

        axs[i].plot(df_trace["date"], mu_preds, linestyle="--", label="Prior (Î¼_pred)")
        axs[i].plot(df_trace["date"], mu_posts, linestyle="-", label="Posterior (Î¼_post)")

        axs[i].set_title(f"{firm_name}'s Kalman State Î¸_{dim}")
        axs[i].legend()
        axs[i].grid(True)

    plt.tight_layout()
    os.makedirs("output/bayesion", exist_ok=True)
    filepath = f"output/bayesion/{firm_name}_Kalman_State.png"
    plt.savefig(filepath, dpi=300)
    # plt.show()

def plot_kalman_gain_heatmap(trace_records, score_cols, step=-1):
    K = trace_records[step]["K_gain"]
    if K is not None:
        plt.figure(figsize=(6, 4))
        sns.heatmap(K, annot=True, fmt=".2f", xticklabels=score_cols, yticklabels=score_cols, cmap="Blues")
        plt.title(f"Kalman Gain Matrix (Step {step})")
        os.makedirs("output/bayesion", exist_ok=True)
        filepath = f"output/bayesion/Kalman Gain Matrix.png"
        plt.savefig(filepath)
        # plt.show()

def plot_kalman_process_graph(score_cols):
    """
        ç»˜åˆ¶ Kalman çŠ¶æ€ä¼ æ’­å›¾ï¼šÎ¸_k(t-1) â†’ Î¸_k(t) â† R_k(t)
        """
    G = nx.DiGraph()

    for col in score_cols:
        G.add_node(f"Î¸_{col}(t-1)", layer="past_state")
        G.add_node(f"Î¸_{col}(t)", layer="current_state")
        G.add_node(f"R_{col}(t)", layer="observation")

        # çŠ¶æ€ä¼ æ’­ & è§‚æµ‹æ›´æ–°
        G.add_edge(f"Î¸_{col}(t-1)", f"Î¸_{col}(t)", label="Ï")
        G.add_edge(f"R_{col}(t)", f"Î¸_{col}(t)", label="K")

    # æ‰‹åŠ¨ layout æŽ’å¸ƒ
    pos = {}
    for i, col in enumerate(score_cols):
        pos[f"Î¸_{col}(t-1)"] = (0, -i)
        pos[f"Î¸_{col}(t)"] = (1.5, -i)
        pos[f"R_{col}(t)"] = (3.0, -i)

    plt.figure(figsize=(10, 1.2 * len(score_cols)))
    nx.draw_networkx_nodes(G, pos, node_size=2200, node_color="#bbdefb")
    nx.draw_networkx_labels(G, pos, font_size=11)
    nx.draw_networkx_edges(G, pos, arrows=True, arrowstyle='->', edge_color='gray', width=1.5)
    nx.draw_networkx_edge_labels(G, pos, edge_labels=nx.get_edge_attributes(G, 'label'), font_size=10)

    plt.title("Kalman State Transition & Observation Update (per dimension)", fontsize=13)
    plt.axis('off')
    plt.tight_layout()
    os.makedirs("output/bayesion", exist_ok=True)
    filepath = f"output/bayesion/Kalman State Transition.png"
    plt.savefig(filepath)
    # plt.show()



# âœ… ç¤ºä¾‹
if __name__ == "__main__":
    example_input = [
        {"firm_id": "BYD", "date": "2025-05-01", "text": "BYD announced a strategic expansion plan."},
        {"firm_id": "BYD", "date": "2025-05-01", "text": "The brand.txt reputation of BYD surged on Google Trends."},
        {"firm_id": "BYD", "date": "2025-05-01", "text": "The company filed 12 new battery patents."},
        {"firm_id": "TSLA", "date": "2025-05-01", "text": "Tesla launched its tokenized loyalty platform."},
        {"firm_id": "TSLA", "date": "2025-05-01",
         "text": "Market perception of Tesla fell sharply after leadership changes."}
    ]

    # df = pd.read_csv("aggregated_result.csv")  # æˆ– run_pipeline è¾“å‡º
    df = run_pipeline(example_input)
    score_cols = ['executive.txt', 'brand.txt', 'patent.txt', 'crypto.txt', 'reputation']

    state_df = run_state_estimation(df, score_cols)
    print(state_df.head())