# åŠŸèƒ½ï¼šç»„ç»‡å…¨æµç¨‹ï¼Œè¾“å…¥åŸå§‹è®°å½•ï¼Œè¾“å‡º R_{i,t}^{(k)} èšåˆç»“æœ

from LLM_signal_generation.preprocess import classify_capability_dimension
from LLM_signal_generation.embedder import SentenceEmbedder
from LLM_signal_generation.aggregator import aggregate_scores_by_firm_time
from LLM_signal_generation.scorer import Scorer
from util import load_dimension_examples_from_files

from sentence_transformers import SentenceTransformer
import pandas as pd
import os
from typing import List, Dict

# âœ… åˆå§‹åŒ–åµŒå…¥å™¨ï¼ˆç”¨äºå¥å­å‘é‡æå–ï¼‰
embedder = SentenceEmbedder()

# âœ… åŠ è½½ç»´åº¦æ ·ä¾‹ï¼ˆæŒ‰æ–‡æœ¬æ–‡ä»¶ç®¡ç†ï¼‰
base_dir = os.path.dirname(os.path.abspath(__file__))  # è·å– main.py æ‰€åœ¨ç›®å½•
example_dir = os.path.join(base_dir, "scorer_examples")
DIMENSION_EXAMPLES = load_dimension_examples_from_files(example_dir)

# âœ… åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆMiniLM æˆ–å¯æ¢ FinBERTï¼‰
model = SentenceTransformer("all-MiniLM-L6-v2")

# âœ… åˆå§‹åŒ– Scorerï¼ˆä¸€æ¬¡æ€§ç¼–ç  + ç¼“å­˜ï¼‰
scorer = Scorer(model, DIMENSION_EXAMPLES)

def run_pipeline(records: List[Dict]) -> pd.DataFrame:
    """
    æ ¸å¿ƒæ‰§è¡Œå‡½æ•°ï¼š
    è¾“å…¥åŸå§‹æ–‡æœ¬æ•°æ®ï¼ŒæŒ‰èƒ½åŠ›ç»´åº¦åˆ†ç±»å¹¶è°ƒç”¨è¯„åˆ†å‡½æ•° â†’ æ±‡æ€»æ‰“åˆ† â†’ èšåˆè¾“å‡ºèƒ½åŠ›è¡¨

    å‚æ•°ï¼š
        records: List of dictsï¼Œç»“æ„å¦‚ä¸‹ï¼š
            {
                'firm_id': str,
                'date': str,
                'text': str
            }

    è¿”å›ï¼š
        pd.DataFrame: èšåˆç»“æœï¼Œæ¯è¡Œæ˜¯å…¬å¸/æ—¶é—´ï¼Œåˆ—æ˜¯å„èƒ½åŠ›ç»´åº¦çš„è¯„åˆ†å€¼
    """
    scored_items = []

    for record in records:
        firm_id = record["firm_id"]
        date = record["date"]
        text = record["text"]

        print("\nğŸ“ Input Text:", text)

        # Step 1: è·å–è¯­ä¹‰å‘é‡è¡¨ç¤ºï¼ˆå¯é€‰ï¼‰
        embedding = embedder.encode([text])[0]
        print("ğŸ“ Embedding vector (shape):", embedding.shape)

        # Step 2: åˆ†ç±»è¯¥å¥å­å±äºå“ªç§èƒ½åŠ›ç»´åº¦ï¼ˆåˆ†ç±»å™¨è¾“å‡ºï¼‰
        dimension = classify_capability_dimension(text)
        print("ğŸ·ï¸  Classified Dimension:", dimension)

        # Step 3: ç›´æ¥è°ƒç”¨ scorer è¯„åˆ†ï¼ˆæŒ‰åˆ†ç±»ç»´åº¦åŒ¹é…ï¼‰
        score_result = scorer.score_all(text, top_k=1)

        # Step 4: è·å–è¯¥ç»´åº¦ä¸‹çš„ç›¸ä¼¼åº¦
        score = score_result.get(dimension, [(None, 0.0)])[0][1]
        print(f"ğŸ¯ Score for {dimension}: {score:.4f}")

        # Step 5: æ•´ç†ä¸ºç»“æ„åŒ–è®°å½•
        scored_items.append({
            "firm_id": firm_id,
            "date": date,
            "score_name": dimension,
            "score_value": score
        })

    # Step 6: èšåˆç»“æœ
    df = aggregate_scores_by_firm_time(scored_items)
    print("\nğŸ“Š Aggregated Result:")
    print(df)

    return df


# âœ… ç¤ºä¾‹æµ‹è¯•
if __name__ == "__main__":
    example_input = [
        {"firm_id": "BYD", "date": "2025-05-01", "text": "BYD announced a strategic expansion plan."},
        {"firm_id": "BYD", "date": "2025-05-01", "text": "The reputation of BYD surged on Google Trends."},
        {"firm_id": "BYD", "date": "2025-05-01", "text": "The company filed 12 new battery patents."},
        {"firm_id": "TSLA", "date": "2025-05-01", "text": "Tesla launched its tokenized loyalty platform."},
        {"firm_id": "TSLA", "date": "2025-05-01", "text": "Market perception of Tesla fell sharply after leadership changes."}
    ]

    df_result = run_pipeline(example_input)
    print("\nâœ… Pipeline finished.")

